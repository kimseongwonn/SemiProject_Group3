{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대여소 ID, 구 단위 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26       ST-975\n",
      "179      ST-837\n",
      "180      ST-836\n",
      "181      ST-835\n",
      "182      ST-834\n",
      "         ...   \n",
      "3208    ST-1066\n",
      "3209    ST-1065\n",
      "3210    ST-1064\n",
      "3211    ST-1063\n",
      "3212    ST-1062\n",
      "Name: 대여소_ID, Length: 224, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciw96\\AppData\\Local\\Temp\\ipykernel_28288\\3686428421.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  대여소_data['주소1'] = data['주소1'].str.extract(r'(\\S+)구')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data= pd.read_csv('../../Data/따릉이/서울시 따릉이대여소 마스터 정보.csv',encoding='cp949')\n",
    "\n",
    "대여소_data = data[['대여소_ID', '주소1']]\n",
    "\n",
    "대여소_data['주소1'] = data['주소1'].str.extract(r'(\\S+)구')\n",
    "\n",
    "\n",
    "강서_대여소_ID = 대여소_data.loc[대여소_data['주소1'] == '강서', '대여소_ID']\n",
    "강서_대여소_ID_df = pd.DataFrame({'대여소_ID': 강서_대여소_ID})\n",
    "\n",
    "강서_대여소_ID_df.to_csv('강서_따릉이_대여소_ID.csv', index=False)\n",
    "\n",
    "print(강서_대여소_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../../Data/따릉이/서울시 따릉이대여소 마스터 정보.csv', encoding='cp949')\n",
    "\n",
    "# '대여소_ID'와 '주소1' 열 선택\n",
    "대여소_data = data[['대여소_ID', '주소1']]\n",
    "\n",
    "# '주소1' 열에서 구 정보 추출하여 새로운 열 추가\n",
    "대여소_data['구'] = data['주소1'].str.extract(r'(\\S+)구')\n",
    "\n",
    "# 대여소를 구별로 묶기\n",
    "구_data = 대여소_data.groupby('구')['대여소_ID'].apply(list).reset_index()\n",
    "\n",
    "print(구_data)\n",
    "\n",
    "\n",
    "# 강남_대여소_ID = 대여소_data.loc[대여소_data['주소1'] == '강남', '대여소_ID']\n",
    "# 강남_대여소_ID_df = pd.DataFrame({'대여소_ID': 강남_대여소_ID})\n",
    "\n",
    "#강남_대여소_ID_df.to_csv('강남_따릉이_대여소_ID.csv', index=False)\n",
    "\n",
    "# print(강남_대여소_ID)\n",
    "# print(len(강남_대여소_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따릉이 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './전처리전작업/따릉이/tpss_bcycl_od_statnhm_202309/tpss_bcycl_od_statnhm_20230905.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/전처리전작업/따릉이/tpss_bcycl_od_statnhm_202301\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m data2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./전처리전작업/따릉이/tpss_bcycl_od_statnhm_202309/tpss_bcycl_od_statnhm_20230905.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp949\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m data2 \u001b[38;5;241m=\u001b[39m data2[data2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m집계_기준\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m도착시간\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(data2)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './전처리전작업/따릉이/tpss_bcycl_od_statnhm_202309/tpss_bcycl_od_statnhm_20230905.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = '/전처리전작업/따릉이/tpss_bcycl_od_statnhm_202301'\n",
    "data2 = pd.read_csv('./전처리전작업/따릉이/tpss_bcycl_od_statnhm_202309/tpss_bcycl_od_statnhm_20230905.csv', encoding='cp949')\n",
    "data2 = data2[data2['집계_기준'] != '도착시간']\n",
    "print(data2)\n",
    "따릉이_data = data2[['기준_날짜', '기준_시간대', '시작_대여소_ID', '종료_대여소_ID', '전체_건수','시작_대여소명']]\n",
    "\n",
    "# 출발 대여소 ID가 강남구 대여소 ID에 해당하는지 확인하는 조건 추가\n",
    "강서출발_mask = 따릉이_data['시작_대여소_ID'].isin(강서_대여소_ID)\n",
    "\n",
    "# 도착 대여소 ID가 강남구 대여소 ID에 해당하는지 확인하는 조건 추가\n",
    "강서도착_mask = 따릉이_data['종료_대여소_ID'].isin(강서_대여소_ID)\n",
    "\n",
    "# 출발 혹은 도착 대여소 ID가 강남구 대여소 ID에 해당하는 데이터만 남기기\n",
    "강서_따릉이_data = 따릉이_data[강서출발_mask | 강서도착_mask]\n",
    "# 시작 대여소명에서 동만 추출하여 새로운 열 추가하기\n",
    "강서_따릉이_data['시작_대여소명'] = 강서_따릉이_data['시작_대여소명'].str.split('_').str[0]\n",
    "\n",
    "print(강서_따릉이_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "굳이 할 필요 없던거.... \n",
    "강남구 하루 이용 횟수 출발, 도착"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강남에서 출발한 대여 건수: 5666\n",
      "강남으로 도착한 대여 건수: 5476\n"
     ]
    }
   ],
   "source": [
    "\n",
    "강남_출발_num = 0\n",
    "강남_도착_num = 0\n",
    "\n",
    "for i,따릉이 in 강남_따릉이_data.iterrows():\n",
    "    시작_대여소_ID = 따릉이['시작_대여소_ID']\n",
    "    종료_대여소_ID = 따릉이['종료_대여소_ID']\n",
    "  \n",
    "    if 시작_대여소_ID in 강남_대여소_ID_df.values:\n",
    "        강남_출발_num += 따릉이['전체_건수']\n",
    "    \n",
    "    if 종료_대여소_ID in 강남_대여소_ID_df.values:\n",
    "        강남_도착_num += 따릉이['전체_건수']\n",
    "\n",
    "\n",
    "print(\"강남에서 출발한 대여 건수:\", 강남_출발_num)\n",
    "print(\"강남으로 도착한 대여 건수:\", 강남_도착_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기상청 데이터\n",
    "\n",
    "기온 : 평균 기온? 최고 최저는 편차가 심하면 못 쓸 가능성 높음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \\t\\t지점번호         지점명   일시  평균기온(℃) 최고기온(℃)  \\t최고기온시각 최저기온(℃)  최저기온시각일교차\n",
      "108       서울  2023-01-01 -0.2      3.8   13:43      -4.3   23:50        8.1\n",
      "108       서울  2023-01-02 -4.5     -0.4   15:25      -7.4   08:04        7.0\n",
      "108       서울  2023-01-03 -5.0      0.6   15:55      -9.0   05:51        9.6\n",
      "108       서울  2023-01-04 -1.8      3.3   15:10      -5.7   02:29        9.0\n",
      "108       서울  2023-01-05 -1.6      3.6   15:36      -5.6   07:49        9.2\n",
      "..       ...         ...  ...      ...     ...       ...     ...        ...\n",
      "108       서울  2023-12-27  1.5      6.8   15:49      -2.8   08:13        9.6\n",
      "108       서울  2023-12-28  1.2      4.4   14:53      -1.7   06:20        6.1\n",
      "108       서울  2023-12-29  1.3      4.6   14:38      -1.5   07:25        6.1\n",
      "108       서울  2023-12-30  0.6      2.1   23:54      -0.9   02:37        3.0\n",
      "108       서울  2023-12-31  2.1      4.3   15:50       0.6   23:43        3.7\n",
      "\n",
      "[365 rows x 8 columns]\n",
      "108   -0.2\n",
      "108   -4.5\n",
      "108   -5.0\n",
      "108   -1.8\n",
      "108   -1.6\n",
      "      ... \n",
      "108    1.5\n",
      "108    1.2\n",
      "108    1.3\n",
      "108    0.6\n",
      "108    2.1\n",
      "Name: 일시, Length: 365, dtype: float64\n",
      "        기준_날짜  평균_기온  최고_기온  최저_기온\n",
      "108  20230101   -0.2    3.8   -4.3\n",
      "108  20230102   -4.5   -0.4   -7.4\n",
      "108  20230103   -5.0    0.6   -9.0\n",
      "108  20230104   -1.8    3.3   -5.7\n",
      "108  20230105   -1.6    3.6   -5.6\n",
      "..        ...    ...    ...    ...\n",
      "108  20231227    1.5    6.8   -2.8\n",
      "108  20231228    1.2    4.4   -1.7\n",
      "108  20231229    1.3    4.6   -1.5\n",
      "108  20231230    0.6    2.1   -0.9\n",
      "108  20231231    2.1    4.3    0.6\n",
      "\n",
      "[365 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def convert_date_to_numeric(date):\n",
    "    date_str = str(date).replace('-', '')\n",
    "    return int(date_str)\n",
    "\n",
    "data3 = pd.read_csv('./전처리전작업/기상청/기상청.csv',encoding='cp949',skiprows=8)\n",
    "열이름 = ['기준_날짜','평균_기온','최고_기온']\n",
    "기온 = data3.iloc[:,1:4]\n",
    "기온.columns = 열이름\n",
    "기온['최저_기온'] = data3.iloc[:,5]\n",
    "기온['기준_날짜'] = 기온['기준_날짜'].apply(convert_date_to_numeric)\n",
    "print(기온)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강수량 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        기준_날짜   강수량\n",
      "5    20230106   3.9\n",
      "6    20230107   0.1\n",
      "11   20230112   0.0\n",
      "12   20230113  37.3\n",
      "13   20230114   1.6\n",
      "..        ...   ...\n",
      "353  20231220   0.8\n",
      "357  20231224   1.1\n",
      "358  20231225   0.7\n",
      "363  20231230  13.1\n",
      "364  20231231   4.7\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def convert_date_to_numeric(date):\n",
    "    date_str = str(date).replace('-', '')\n",
    "    return int(date_str)\n",
    "\n",
    "data4 = pd.read_csv('./전처리전작업/기상청/강수량.csv',encoding='cp949',skiprows=6)\n",
    "data4 = data4.dropna()\n",
    "\n",
    "강수량 = data4[['날짜', '강수량(mm)']]\n",
    "강수량 = 강수량.rename(columns={'날짜': '기준_날짜'})\n",
    "강수량 = 강수량.rename(columns={'강수량(mm)': '강수량'})\n",
    "강수량['기준_날짜'] = 강수량['기준_날짜'].apply(convert_date_to_numeric)\n",
    "\n",
    "print(강수량)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세먼지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         기준_날짜  미세먼지\n",
      "0     20230101  52.0\n",
      "25    20230102  24.0\n",
      "50    20230103  29.0\n",
      "75    20230104  35.0\n",
      "100   20230105  47.0\n",
      "...        ...   ...\n",
      "9000  20231227  69.0\n",
      "9025  20231228  48.0\n",
      "9050  20231229  44.0\n",
      "9075  20231230  42.0\n",
      "9100  20231231  23.0\n",
      "\n",
      "[365 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data5 = pd.read_csv('./전처리전작업/기상청/미세먼지.csv',encoding='cp949')\n",
    "\n",
    "미세먼지_강남구_data = data5[data5['측정소명']=='강남구']\n",
    "미세먼지_강남구_data = 미세먼지_강남구_data.rename(columns={'측정일시': '기준_날짜'})\n",
    "미세먼지_강남구_data = 미세먼지_강남구_data.rename(columns={'미세먼지(㎍/㎥)': '미세먼지'})\n",
    "미세먼지 = 미세먼지_강남구_data[['기준_날짜','미세먼지']]\n",
    "\n",
    "print(미세먼지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 폴더 안 파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "데이터_목록 = []\n",
    "\n",
    "강서_대여소_ID = pd.read_csv('./전처리1/강서_따릉이_대여소_ID.csv',encoding='utf-8')\n",
    "강서_대여소_ID = 강서_대여소_ID['대여소_ID']\n",
    "\n",
    "for 연도 in range(202301, 202313):\n",
    "    폴더_경로 = f'./전처리1/tpss_bcycl_od_statnhm_{연도}/'\n",
    "\n",
    "    # 폴더 내의 모든 파일 목록 가져오기\n",
    "    파일_목록 = os.listdir(폴더_경로)\n",
    "\n",
    "    # CSV 파일만 필터링\n",
    "    csv_파일 = [파일 for 파일 in 파일_목록 if 파일.endswith('.csv')]\n",
    "\n",
    "    # 각 CSV 파일을 읽어오기\n",
    "    for 파일 in csv_파일:\n",
    "        파일_경로 = os.path.join(폴더_경로, 파일)\n",
    "        try:\n",
    "            데이터 = pd.read_csv(파일_경로, encoding='cp949')\n",
    "            if '기준_시간' in 데이터.columns and '기준_시간대' not in 데이터.columns:\n",
    "                데이터.rename(columns={'기준_시간': '기준_시간대'}, inplace=True)\n",
    "            if '시작_대여소' in 데이터.columns and '시작_대여소_ID' not in 데이터.columns:\n",
    "                데이터.rename(columns={'시작_대여소': '시작_대여소_ID'}, inplace=True)\n",
    "            if '종료_대여소' in 데이터.columns and '종료_대여소_ID' not in 데이터.columns:\n",
    "                데이터.rename(columns={'종료_대여소': '종료_대여소_ID'}, inplace=True)\n",
    "            if '전체건수' in 데이터.columns and '전체_건수' not in 데이터.columns:\n",
    "                데이터.rename(columns={'전체건수': '전체_건수'}, inplace=True)    \n",
    "                \n",
    "            데이터_목록.append(데이터)\n",
    "        except Exception as e:\n",
    "            print(f\"{파일_경로}에서 오류 발생: {e}\")\n",
    "\n",
    "# 데이터프레임들을 하나로 병합\n",
    "데이터_01 = pd.concat(데이터_목록, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차 전처리\n",
    "-전체 이용 시간이 0이거나 전체 이용 거리가 0인거 제거\n",
    "- 아직 시간이 0시로 돌아가는 거(?) 확인해야함\n",
    "- 여기서  8600만 ->  8200만으로 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터_01 = 데이터_01[(데이터_01['전체_이용_분'] != 0) & (데이터_01['전체_이용_거리'] != 0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차 전처리  + csv\n",
    "- 강남구 자료만 받아옴\n",
    "- 8200 ->  180만개로 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "따릉이_data_1 = 데이터_01[['기준_날짜', '기준_시간대', '시작_대여소_ID', '종료_대여소_ID', '전체_건수','전체_이용_분','전체_이용_거리']]\n",
    "\n",
    "# 출발 대여소 ID가 강남구 대여소 ID에 해당하는지 확인하는 조건 추가\n",
    "강남출발_mask_1 = 따릉이_data_1['시작_대여소_ID'].isin(강남_대여소_ID)\n",
    "\n",
    "# 도착 대여소 ID가 강남구 대여소 ID에 해당하는지 확인하는 조건 추가\n",
    "강남도착_mask_1 = 따릉이_data_1['종료_대여소_ID'].isin(강남_대여소_ID)\n",
    "\n",
    "# 출발 혹은 도착 대여소 ID가 강남구 대여소 ID에 해당하는 데이터만 남기기\n",
    "강남_따릉이_data_1 = 따릉이_data_1[강남출발_mask_1 & 강남도착_mask_1]\n",
    "\n",
    "\n",
    "강남_따릉이_data_1.to_csv('강남_따릉이_data_2023.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 폴더 안의 파일 데이터 가져오기\n",
    "-----------------\n",
    "필요 없어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "데이터_목록 = []\n",
    "\n",
    "# 폴더 경로 \n",
    "for 연도 in range(202301, 202304):\n",
    "    폴더_경로 = f'./전처리전작업/따릉이/tpss_bcycl_od_statnhm_{연도}/'\n",
    "\n",
    "    # 폴더 내의 모든 파일 목록 가져오기\n",
    "    파일_목록 = os.listdir(폴더_경로)\n",
    "\n",
    "    # CSV 파일만 필터링\n",
    "    csv_파일 = [파일 for 파일 in 파일_목록 if 파일.endswith('.csv')]\n",
    "\n",
    "    # 각 CSV 파일을 읽어오기\n",
    "    for 파일 in csv_파일:\n",
    "        파일_경로 = os.path.join(폴더_경로, 파일)\n",
    "        try:\n",
    "            데이터 = pd.read_csv(파일_경로, encoding='cp949')\n",
    "            데이터_목록.append(데이터)\n",
    "        except Exception as e:\n",
    "            print(f\"{파일_경로}에서 오류 발생: {e}\")\n",
    "\n",
    "# 데이터프레임들을 하나로 병합\n",
    "데이터_01_03 = pd.concat(데이터_목록, ignore_index=True)\n",
    "데이터_목록 = []\n",
    "for 연도 in range(202304, 202307):\n",
    "    폴더_경로 = f'./전처리전작업/따릉이/tpss_bcycl_od_statnhm_{연도}/'\n",
    "\n",
    "    # 폴더 내의 모든 파일 목록 가져오기\n",
    "    파일_목록 = os.listdir(폴더_경로)\n",
    "\n",
    "    # CSV 파일만 필터링\n",
    "    csv_파일 = [파일 for 파일 in 파일_목록 if 파일.endswith('.csv')]\n",
    "\n",
    "    # 각 CSV 파일을 읽어오기\n",
    "    for 파일 in csv_파일:\n",
    "        파일_경로 = os.path.join(폴더_경로, 파일)\n",
    "        try:\n",
    "            데이터 = pd.read_csv(파일_경로, encoding='cp949')\n",
    "            데이터_목록.append(데이터)\n",
    "        except Exception as e:\n",
    "            print(f\"{파일_경로}에서 오류 발생: {e}\")\n",
    "\n",
    "데이터_04_06 = pd.concat(데이터_목록, ignore_index=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터_목록 = []\n",
    "for 연도 in range(202307, 202310):\n",
    "    폴더_경로 = f'./전처리전작업/따릉이/tpss_bcycl_od_statnhm_{연도}/'\n",
    "\n",
    "    # 폴더 내의 모든 파일 목록 가져오기\n",
    "    파일_목록 = os.listdir(폴더_경로)\n",
    "\n",
    "    # CSV 파일만 필터링\n",
    "    csv_파일 = [파일 for 파일 in 파일_목록 if 파일.endswith('.csv')]\n",
    "\n",
    "    # 각 CSV 파일을 읽어오기\n",
    "    for 파일 in csv_파일:\n",
    "        파일_경로 = os.path.join(폴더_경로, 파일)\n",
    "        try:\n",
    "            데이터 = pd.read_csv(파일_경로, encoding='cp949')            \n",
    "            if '기준_시간' in 데이터.columns and '기준_시간대' not in 데이터.columns:\n",
    "                데이터.rename(columns={'기준_시간': '기준_시간대'}, inplace=True)\n",
    "            if '시작_대여소' in 데이터.columns and '시작_대여소_ID' not in 데이터.columns:\n",
    "                데이터.rename(columns={'시작_대여소': '시작_대여소_ID'}, inplace=True)\n",
    "            if '종료_대여소' in 데이터.columns and '종료_대여소_ID' not in 데이터.columns:\n",
    "                데이터.rename(columns={'종료_대여소': '종료_대여소_ID'}, inplace=True)\n",
    "            if '전체건수' in 데이터.columns and '전체_건수' not in 데이터.columns:\n",
    "                데이터.rename(columns={'전체건수': '전체_건수'}, inplace=True)    \n",
    "                \n",
    "            데이터_목록.append(데이터)\n",
    "        except Exception as e:\n",
    "            print(f\"{파일_경로}에서 오류 발생: {e}\")\n",
    "\n",
    "데이터_07_09 = pd.concat(데이터_목록, ignore_index=True)\n",
    "\n",
    "데이터_목록 = []\n",
    "for 연도 in range(202310, 202313):\n",
    "    폴더_경로 = f'./전처리전작업/따릉이/tpss_bcycl_od_statnhm_{연도}/'\n",
    "\n",
    "    # 폴더 내의 모든 파일 목록 가져오기\n",
    "    파일_목록 = os.listdir(폴더_경로)\n",
    "\n",
    "    # CSV 파일만 필터링\n",
    "    csv_파일 = [파일 for 파일 in 파일_목록 if 파일.endswith('.csv')]\n",
    "\n",
    "    # 각 CSV 파일을 읽어오기\n",
    "    for 파일 in csv_파일:\n",
    "        파일_경로 = os.path.join(폴더_경로, 파일)\n",
    "        try:\n",
    "            데이터 = pd.read_csv(파일_경로, encoding='cp949')\n",
    "            if '기준_시간' in 데이터.columns and '기준_시간대' not in 데이터.columns:\n",
    "                데이터.rename(columns={'기준_시간': '기준_시간대'}, inplace=True)\n",
    "            if '시작_대여소' in 데이터.columns and '시작_대여소_ID' not in 데이터.columns:\n",
    "                데이터.rename(columns={'시작_대여소': '시작_대여소_ID'}, inplace=True)\n",
    "            if '종료_대여소' in 데이터.columns and '종료_대여소_ID' not in 데이터.columns:\n",
    "                데이터.rename(columns={'종료_대여소': '종료_대여소_ID'}, inplace=True)\n",
    "            if '전체건수' in 데이터.columns and '전체_건수' not in 데이터.columns:\n",
    "                데이터.rename(columns={'전체건수': '전체_건수'}, inplace=True)    \n",
    "                \n",
    "            데이터_목록.append(데이터)\n",
    "        except Exception as e:\n",
    "            print(f\"{파일_경로}에서 오류 발생: {e}\")\n",
    "\n",
    "데이터_10_12 = pd.concat(데이터_목록, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               기준_날짜  기준_시간대 시작_대여소_ID 종료_대여소_ID  전체_건수  전체_이용_분  전체_이용_거리  \\\n",
      "0         20230101.0       0   ST-1590   ST-1590      1        0         0   \n",
      "1         20230101.0       0   ST-2127   ST-2127      1        0         0   \n",
      "2         20230101.0       5   ST-1286   ST-1286      1        0         0   \n",
      "3         20230101.0       5   ST-1780   ST-1780      1        0         0   \n",
      "4         20230101.0       5   ST-2018   ST-2018      2        2         0   \n",
      "...              ...     ...       ...       ...    ...      ...       ...   \n",
      "14990062  20230331.0    1620   ST-2905   ST-2905     10      537     57669   \n",
      "14990063  20230331.0    1715   ST-2905   ST-2905     10      507     45591   \n",
      "14990064  20230331.0    1135   ST-1443    ST-296     11      579     77817   \n",
      "14990065  20230331.0    1605     ST-99     ST-99     12      456     62884   \n",
      "14990066  20230331.0    1805     ST-99     ST-99     12      765     81649   \n",
      "\n",
      "          ?\"기준_날짜\" 집계_기준     시작_대여소명     종료_대여소명  \n",
      "0              NaN   NaN         NaN         NaN  \n",
      "1              NaN   NaN         NaN         NaN  \n",
      "2              NaN   NaN         NaN         NaN  \n",
      "3              NaN   NaN         NaN         NaN  \n",
      "4              NaN   NaN         NaN         NaN  \n",
      "...            ...   ...         ...         ...  \n",
      "14990062       NaN  도착시간  망원1동_041_1  망원1동_041_1  \n",
      "14990063       NaN  도착시간  망원1동_041_1  망원1동_041_1  \n",
      "14990064       NaN  도착시간  한강로동_013_1   여의동_002_1  \n",
      "14990065       NaN  도착시간  자양3동_050_1  자양3동_050_1  \n",
      "14990066       NaN  도착시간  자양3동_050_1  자양3동_050_1  \n",
      "\n",
      "[14990067 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(데이터_01_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             기준_날짜 집계_기준  기준_시간대 시작_대여소_ID      시작_대여소명 종료_대여소_ID     종료_대여소명  \\\n",
      "0         20231001  출발시간       0   ST-3163    목1동_040_2   ST-1997   목1동_015_1   \n",
      "1         20231001  출발시간       0   ST-3011   당산2동_003_4   ST-2807  당산2동_036_1   \n",
      "2         20231001  출발시간       0    ST-401   이문1동_056_1    ST-401  이문1동_056_1   \n",
      "3         20231001  출발시간       0   ST-1714   가양1동_040_2   ST-2031  가양1동_039_8   \n",
      "4         20231001  출발시간       0   ST-2205  남가좌1동_014_1   ST-2905  망원1동_041_1   \n",
      "...            ...   ...     ...       ...          ...       ...         ...   \n",
      "20987266  20231231  도착시간    2355   ST-1609   숭인2동_005_1    ST-271   용신동_054_1   \n",
      "20987267  20231231  도착시간    2355   ST-2305   자양3동_002_1    ST-987  자양3동_004_1   \n",
      "20987268  20231231  출발시간    2355   ST-2481   화곡본동_007_1   ST-2481  화곡본동_007_1   \n",
      "20987269  20231231  도착시간    2355   ST-2742   성내3동_012_1   ST-1061  천호1동_039_1   \n",
      "20987270  20231231  도착시간    2355   ST-3011   당산2동_003_4    ST-280  양평1동_001_1   \n",
      "\n",
      "          전체_건수  전체_이용_분  전체_이용_거리  \n",
      "0             1        4      1040  \n",
      "1             1        8      1700  \n",
      "2             1        0         0  \n",
      "3             1       12      1223  \n",
      "4             1       31      3610  \n",
      "...         ...      ...       ...  \n",
      "20987266      1        9      1046  \n",
      "20987267      1       15      1632  \n",
      "20987268      1        0         0  \n",
      "20987269      1       14      2081  \n",
      "20987270      1        6       914  \n",
      "\n",
      "[20987271 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(데이터_10_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "따릉이_data_1 = 데이터_01_03[['기준_날짜', '기준_시간대', '시작_대여소_ID', '종료_대여소_ID', '전체_건수']]\n",
    "따릉이_data_2 = 데이터_04_06[['기준_날짜', '기준_시간대', '시작_대여소_ID', '종료_대여소_ID', '전체_건수']]\n",
    "따릉이_data_3 = 데이터_07_09[['기준_날짜', '기준_시간대', '시작_대여소_ID', '종료_대여소_ID', '전체_건수']]\n",
    "따릉이_data_4 = 데이터_10_12[['기준_날짜', '기준_시간대', '시작_대여소_ID', '종료_대여소_ID', '전체_건수']]\n",
    "\n",
    "# 출발 대여소 ID가 강남구 대여소 ID에 해당하는지 확인하는 조건 추가\n",
    "강남출발_mask_1 = 따릉이_data_1['시작_대여소_ID'].isin(강남_대여소_ID)\n",
    "강남출발_mask_2 = 따릉이_data_2['시작_대여소_ID'].isin(강남_대여소_ID)\n",
    "강남출발_mask_3 = 따릉이_data_3['시작_대여소_ID'].isin(강남_대여소_ID)\n",
    "강남출발_mask_4 = 따릉이_data_4['시작_대여소_ID'].isin(강남_대여소_ID)\n",
    "\n",
    "# 도착 대여소 ID가 강남구 대여소 ID에 해당하는지 확인하는 조건 추가\n",
    "강남도착_mask_1 = 따릉이_data_1['종료_대여소_ID'].isin(강남_대여소_ID)\n",
    "강남도착_mask_2 = 따릉이_data_2['종료_대여소_ID'].isin(강남_대여소_ID)\n",
    "강남도착_mask_3 = 따릉이_data_3['종료_대여소_ID'].isin(강남_대여소_ID)\n",
    "강남도착_mask_4 = 따릉이_data_4['종료_대여소_ID'].isin(강남_대여소_ID)\n",
    "\n",
    "# 출발 혹은 도착 대여소 ID가 강남구 대여소 ID에 해당하는 데이터만 남기기\n",
    "강남_따릉이_data_1 = 따릉이_data_1[강남출발_mask_1 | 강남도착_mask_1]\n",
    "강남_따릉이_data_2 = 따릉이_data_2[강남출발_mask_2 | 강남도착_mask_2]\n",
    "강남_따릉이_data_3 = 따릉이_data_3[강남출발_mask_3 | 강남도착_mask_3]\n",
    "강남_따릉이_data_4 = 따릉이_data_4[강남출발_mask_4 | 강남도착_mask_4]\n",
    "\n",
    "따릉이_data_1.to_csv('강남_따릉이_data_2023_01.csv',index=False)\n",
    "따릉이_data_2.to_csv('강남_따릉이_data_2023_02.csv',index=False)\n",
    "따릉이_data_3.to_csv('강남_따릉이_data_2023_03.csv',index=False)\n",
    "따릉이_data_4.to_csv('강남_따릉이_data_2023_04.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "따릉이_data_4 = 데이터_10_12[['기준_날짜', '기준_시간대', '시작_대여소_ID', '종료_대여소_ID', '전체_건수']]\n",
    "강남출발_mask_4 = 따릉이_data_4['시작_대여소_ID'].isin(강남_대여소_ID)\n",
    "강남도착_mask_4 = 따릉이_data_4['종료_대여소_ID'].isin(강남_대여소_ID)\n",
    "강남_따릉이_data_4 = 따릉이_data_4[강남출발_mask_4 | 강남도착_mask_4]\n",
    "따릉이_data_4.to_csv('강남_따릉이_data_2023_04.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
